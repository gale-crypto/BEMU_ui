{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRxh1MUwnJyiNEZrRnriYI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gale-crypto/BEMU_ui/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXPqKkn4nBtx"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Fine-tune a smaller model for direct score prediction (regression)\n",
        "This script fine-tunes DistilBERT to predict risk scores (0-100) directly from text\n",
        "No MNLI conversion needed - trains on text and score pairs directly\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "\n",
        "# Configuration\n",
        "BASE_MODEL = \"distilbert-base-uncased\"  # ~260MB, can be quantized to ~65MB\n",
        "\n",
        "OUTPUT_DIR = Path(\"models\")\n",
        "MODEL_OUTPUT_NAME = \"custom-score-model\"\n",
        "\n",
        "# Dataset configuration\n",
        "CUSTOM_DATASET_PATH = \"data/train.csv\"  # Path to your dataset (CSV or JSON)\n",
        "# Dataset format: CSV with \"text,score\" columns\n",
        "# - text: The email/text content\n",
        "# - score: Risk score (0-100)\n",
        "\n",
        "def load_custom_dataset(dataset_path):\n",
        "    \"\"\"\n",
        "    Load custom dataset from file (CSV or JSON)\n",
        "    Expected format:\n",
        "    - CSV: columns should be \"text\", \"score\" (score is 0-100)\n",
        "    - JSON: array of objects with \"text\", \"score\" fields\n",
        "    Returns dataset with text and score columns for regression\n",
        "    \"\"\"\n",
        "    dataset_path = Path(dataset_path)\n",
        "\n",
        "    if not dataset_path.exists():\n",
        "        raise FileNotFoundError(f\"Dataset file not found: {dataset_path}\")\n",
        "\n",
        "    print(f\"Loading custom dataset from: {dataset_path}\")\n",
        "\n",
        "    if dataset_path.suffix == \".csv\":\n",
        "        dataset = load_dataset(\"csv\", data_files=str(dataset_path), split=\"train\")\n",
        "    elif dataset_path.suffix == \".json\":\n",
        "        dataset = load_dataset(\"json\", data_files=str(dataset_path), split=\"train\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported dataset format: {dataset_path.suffix}. Use CSV (.csv) or JSON (.json)\")\n",
        "\n",
        "    # Verify required columns\n",
        "    if \"text\" not in dataset.column_names or \"score\" not in dataset.column_names:\n",
        "        raise ValueError(f\"Dataset must have 'text' and 'score' columns. Found: {dataset.column_names}\")\n",
        "\n",
        "    # Convert scores to float and validate range\n",
        "    def validate_scores(examples):\n",
        "        scores = []\n",
        "        for score in examples[\"score\"]:\n",
        "            # Convert to float explicitly (not int)\n",
        "            if isinstance(score, str):\n",
        "                score_float = float(score)\n",
        "            else:\n",
        "                score_float = float(score)\n",
        "            # Clamp to 0-100 range\n",
        "            score_float = max(0.0, min(100.0, score_float))\n",
        "            scores.append(score_float)\n",
        "        return {\"score\": scores}\n",
        "\n",
        "    dataset = dataset.map(validate_scores, batched=True)\n",
        "\n",
        "    # Show score distribution\n",
        "    scores = dataset[\"score\"]\n",
        "    print(f\"âœ… Loaded {len(dataset)} samples\")\n",
        "    print(f\"   Score range: {min(scores):.1f} - {max(scores):.1f}\")\n",
        "    print(f\"   Score mean: {np.mean(scores):.1f}, std: {np.std(scores):.1f}\")\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def prepare_dataset(tokenizer, max_length=512):\n",
        "    \"\"\"\n",
        "    Load and prepare dataset for regression (score prediction)\n",
        "    Tokenizes text and keeps scores as labels for regression\n",
        "    \"\"\"\n",
        "    # Load custom dataset\n",
        "    if not CUSTOM_DATASET_PATH:\n",
        "        raise ValueError(\"CUSTOM_DATASET_PATH must be provided\")\n",
        "    dataset = load_custom_dataset(CUSTOM_DATASET_PATH)\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        # Tokenize text only (not premise-hypothesis pairs)\n",
        "        tokenized = tokenizer(\n",
        "            examples[\"text\"],\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            padding=\"max_length\",\n",
        "        )\n",
        "        # Keep scores as labels for regression\n",
        "        # IMPORTANT: Convert to float list explicitly (regression requires float, not int)\n",
        "        # PyTorch will create FloatTensor from list of floats, LongTensor from list of ints\n",
        "        scores = [float(score) for score in examples[\"score\"]]\n",
        "        tokenized[\"labels\"] = scores\n",
        "        return tokenized\n",
        "\n",
        "    # Tokenize dataset\n",
        "    print(\"Tokenizing dataset...\")\n",
        "    columns_to_remove = [col for col in dataset.column_names if col != \"text\" and col != \"score\"]\n",
        "    tokenized_dataset = dataset.map(\n",
        "        tokenize_function,\n",
        "        batched=True,\n",
        "        remove_columns=columns_to_remove,\n",
        "    )\n",
        "\n",
        "    return tokenized_dataset\n",
        "\n",
        "def main():\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Fine-tune Small Model for Direct Score Prediction (Regression)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Create output directory\n",
        "    OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "    model_output_dir = OUTPUT_DIR / MODEL_OUTPUT_NAME\n",
        "\n",
        "    print(f\"\\nBase Model: {BASE_MODEL}\")\n",
        "    print(f\"Output: {model_output_dir}\")\n",
        "\n",
        "    # Load tokenizer and model\n",
        "    print(f\"\\n[Step 1/5] Loading {BASE_MODEL}...\")\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
        "        # For regression: num_labels=1 (single score output)\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            BASE_MODEL,\n",
        "            num_labels=1,  # Regression: single score output (0-100)\n",
        "            problem_type=\"regression\",  # Set problem type to regression\n",
        "        )\n",
        "        print(\"âœ… Model loaded successfully (regression mode)\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error loading model: {e}\")\n",
        "        return False\n",
        "\n",
        "    # Prepare dataset\n",
        "    print(f\"\\n[Step 2/5] Preparing dataset for regression...\")\n",
        "    try:\n",
        "        train_dataset = prepare_dataset(tokenizer)\n",
        "\n",
        "        # Use a subset for faster training (remove this for full training)\n",
        "        # train_dataset = train_dataset.select(range(10000))  # Use 10k samples for testing\n",
        "\n",
        "        print(f\"âœ… Dataset prepared: {len(train_dataset)} samples\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error preparing dataset: {e}\")\n",
        "        print(\"\\nðŸ’¡ Installing required packages:\")\n",
        "        print(\"   pip install datasets\")\n",
        "        return False\n",
        "\n",
        "    # Custom data collator that ensures labels are float tensors for regression\n",
        "    class RegressionDataCollator(DataCollatorWithPadding):\n",
        "        def __call__(self, features):\n",
        "            batch = super().__call__(features)\n",
        "            # Ensure labels are float tensors (regression requires float, not Long/int)\n",
        "            if \"labels\" in batch:\n",
        "                labels = batch[\"labels\"]\n",
        "                if isinstance(labels, torch.Tensor):\n",
        "                    batch[\"labels\"] = labels.float()\n",
        "                elif isinstance(labels, list):\n",
        "                    batch[\"labels\"] = torch.tensor(labels, dtype=torch.float32)\n",
        "            return batch\n",
        "\n",
        "    data_collator = RegressionDataCollator(tokenizer=tokenizer)\n",
        "\n",
        "    # Training arguments\n",
        "    print(f\"\\n[Step 3/5] Setting up training (regression)...\")\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=str(model_output_dir / \"checkpoints\"),\n",
        "        num_train_epochs=5,  # More epochs for regression\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.01,\n",
        "        learning_rate=2e-5,  # Standard learning rate for fine-tuning\n",
        "        logging_dir=str(model_output_dir / \"logs\"),\n",
        "        logging_steps=100,\n",
        "        save_strategy=\"epoch\",\n",
        "        eval_strategy=\"no\",\n",
        "        load_best_model_at_end=False,\n",
        "        push_to_hub=False,\n",
        "        report_to=\"none\",\n",
        "        # Regression-specific: use MSE loss (default for regression)\n",
        "        metric_for_best_model=\"loss\",\n",
        "        greater_is_better=False,\n",
        "    )\n",
        "\n",
        "    # Create trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    print(f\"\\n[Step 4/5] Training model...\")\n",
        "    print(\"This will take a while (hours) depending on your hardware...\")\n",
        "    print(\"Consider using GPU for faster training.\\n\")\n",
        "\n",
        "    try:\n",
        "        trainer.train()\n",
        "        print(\"âœ… Training completed\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Training error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "    # Save model\n",
        "    print(f\"\\n[Step 5/5] Saving fine-tuned model...\")\n",
        "    try:\n",
        "        trainer.save_model(str(model_output_dir))\n",
        "        tokenizer.save_pretrained(str(model_output_dir))\n",
        "        print(f\"âœ… Model saved to: {model_output_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error saving model: {e}\")\n",
        "        return False\n",
        "\n",
        "    # Test model with example texts\n",
        "    print(f\"\\n[Testing] Testing model with example texts...\")\n",
        "    test_examples = [\n",
        "        \"Hi! Just following up when you have a moment. Thanks.\",\n",
        "        \"This is unacceptable and needs to be fixed immediately.\",\n",
        "        \"Please confirm if you can deliver this by Friday.\",\n",
        "        \"I'm disappointed with your performance on this project.\",\n",
        "        \"This is your final warning. Legal action will follow if not resolved.\",\n",
        "        \"This issue has reached a critical point and can no longer be handled informally. Your continued failure to address the matter has caused measurable damage. We are preparing to involve legal counsel if this is not resolved immediately. All communications regarding this issue are now being preserved. Respond without delay.\",\n",
        "        \"This situation has now gone beyond a minor oversight. We clearly outlined expectations, and they were not met. The impact of this failure is affecting broader deliverables. I need a concrete plan to address this immediately. If we donâ€™t see corrective action, weâ€™ll have to consider further steps.\"\n",
        "    ]\n",
        "\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"Test Predictions:\")\n",
        "        print(\"=\" * 60)\n",
        "        for example_text in test_examples:\n",
        "            # Tokenize\n",
        "            inputs = tokenizer(\n",
        "                example_text,\n",
        "                return_tensors=\"pt\",\n",
        "                truncation=True,\n",
        "                max_length=512,\n",
        "                padding=\"max_length\",\n",
        "            )\n",
        "\n",
        "            # Predict\n",
        "            outputs = model(**inputs)\n",
        "            predicted_score = outputs.logits.item()\n",
        "\n",
        "            # Clamp to 0-100 range\n",
        "            predicted_score = max(0.0, min(100.0, predicted_score))\n",
        "\n",
        "            print(f\"\\nText: \\\"{example_text[:60]}{'...' if len(example_text) > 60 else ''}\\\"\")\n",
        "            print(f\"Predicted Score: {predicted_score:.2f}\")\n",
        "            print(f\"Risk Band: \", end=\"\")\n",
        "            if predicted_score < 60:\n",
        "                print(\"0-59 (Low Risk)\")\n",
        "            elif predicted_score < 80:\n",
        "                print(\"60-79 (Medium Risk)\")\n",
        "            else:\n",
        "                print(\"80-100 (High Risk)\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"âœ… SUCCESS! Regression model fine-tuned and saved\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nModel Details:\")\n",
        "    print(f\"  - Type: Regression (predicts score 0-100 directly)\")\n",
        "    print(f\"  - Input: Text only\")\n",
        "    print(f\"  - Output: Single score value (0-100)\")\n",
        "    print(f\"\\nNext steps:\")\n",
        "    print(f\"1. Convert to ONNX: python convert_finetuned_to_onnx.py --model {model_output_dir}\")\n",
        "    print(f\"2. Quantize: python quantize_onnx_model.py --input models/custom-score-model-onnx/model.onnx --output models/custom-score-model-65mb.onnx\")\n",
        "    print(f\"3. Update Chrome extension to use regression model (different inference logic)\")\n",
        "\n",
        "    return True\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    success = main()\n",
        "    sys.exit(0 if success else 1)\n",
        "\n"
      ]
    }
  ]
}